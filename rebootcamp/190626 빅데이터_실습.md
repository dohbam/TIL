### Clustering이란? (복습)

* Python - 안 배우신 분들 codecademy에서 공부하시면. JAVA보다 직관적으로 이해하기 쉬울 거예요.

> 시작하기 전에, 
>
> [data](<http://kdd.snu.ac.kr/python/>) : cluster2 download
>
> [강의자료](<http://edu.ssafy.com/data/upload_files/crossUpload/openLrn/ebook/unzip/A2019062515433036800/index.html>)

## Tools

### Weka

* Java 기반

* Data mining tool

* clustering algorithm들 제공

* download : Java 버전이 맞아야 돌아가기 때문에 자바 포함 버전 다운받길 추천

* 실행 > explorer

  * preprocess > open file > cluster2.arff 열기

    * .arff 파일 메모장에서 열어볼 수 있음
    * attribute : 속성, column 이름. 뒤에 가질 수 있는 값 표시(real / {A, B, C} 등)
    * csv 파일도 다룰 수 있음
    * input data x, y, label 확인 가능

  * cluster 메뉴에서  algorithm 선택 - 입력값 있는 쪽 누르면 새 창 뜸

    * distanceFunction 선택 가능 : EuclideanDistance 사용

    * numClusters : 4

    * 결과

      ```text
      === Run information ===
      
      Scheme:       weka.clusterers.SimpleKMeans -init 0 -max-candidates 100 -periodic-pruning 10000 -min-density 2.0 -t1 -1.25 -t2 -1.0 -N 4 -A "weka.core.EuclideanDistance -R first-last" -I 500 -num-slots 1 -S 10
      Relation:     /cluster2
      Instances:    1300
      Attributes:   3
                    x
                    y
                    label
      Test mode:    evaluate on training data
      
      
      === Clustering model (full training set) ===
      
      
      kMeans
      ======
      
      Number of iterations: 11
      Within cluster sum of squared errors: 65.55335302084616
      
      Initial starting points (random):
      
      Cluster 0: 1.049088,0.21046,C
      Cluster 1: 1.107416,0.521902,C
      Cluster 2: 0.247297,0.326105,B
      Cluster 3: 1.064895,0.240888,C
      
      Missing values globally replaced with mean/mode
      
      Final cluster centroids:
                               Cluster#
      Attribute    Full Data          0          1          2          3
                    (1300.0)    (333.0)    (400.0)    (200.0)    (367.0)
      ==================================================================
      x               0.7361     0.6768     0.7108     0.2028     1.1081
      y                0.713     0.5213     1.2501     0.4073     0.4682
      label                C          C          A          B          C
      
      
      
      
      Time taken to build model (full training data) : 0.02 seconds
      
      === Model and evaluation on training set ===
      
      Clustered Instances
      
      0       333 ( 26%)
      1       400 ( 31%)
      2       200 ( 15%)
      3       367 ( 28%)
      ```

    * 우클릭 > visualize > x, y 선택해서 확인 가능

### Anaconda

* python

* anaconda distribution download : python 3.7 version으로

* jupyter notebook

  * 셀 단위 관리 가능해서 편리

  > 강사님 파이썬이랑 주피터노트북 설명해주신다. 우리는 이미 배웠는데... 매일 반복되는 시간낭비 ㅎ 사피 운영 진짜... 답도 없다.

  * restart and run all 등 기능 설명 열심히 해주시는 중
  * 창을 닫아도 background에서 running 중이니 큰 프로젝트를 할 때에는 close and helt로 닫거나 따로 shutdown을 해서 관리해주는 편이 좋음. 

* jn에서 작업

  > bash_profile에서 alias로 줄임말 등록해놓음
  >
  > taki ) bashrc, bash_profile 어디에 해도 괜찮. bash_profile에서 하지 않으면 git bash에서 warning을 띄워서 bash_profile에 한 것뿐

  * 아나콘다 설치시 판다스 자동으로 따라옴. import해서 사용.
  * df.values로 array 형태로 변환
  * output 한 번 클릭 - scroll - 두 번 클릭 - 아예 접어줌
  * matplotlib.pyplot : `pyplot` : 파일로 그래프 만들어주는 라이브러리
    * jn에 바로 보여주도록 `%matplotlib inline` 입력
  * plotting the dataset
  * choosing colormaps : `cmap="tab10"`
    * matplotlib.org 에서 취향에 맞는 colormap 찾아서 사용 가능
  * `sklearn.cluster` 라이브러리 사용. `KMeans`(클래스) 포함 다양한 알고리즘 제공.
  * `Bigdata_practice`에 내용정리.

  > 이론 아침에 인강으로 들었다고 말하면 안 되나...

* Hierarchical Clustering : 가장 가까운 애들끼리 합쳐나간다. '가까운'을 알아내기 위해 거리를 설정하는 방법에 따라 달라짐

  * Weka에서 실습

  * linktype, cluster 개수 설정 가능

    * single, 4

      ```text
      === Run information ===
      
      Scheme:       weka.clusterers.HierarchicalClusterer -N 4 -L SINGLE -P -A "weka.core.EuclideanDistance -R first-last"
      Relation:     /cluster2
      Instances:    1300
      Attributes:   3
                    x
                    y
                    label
      Test mode:    evaluate on training data
      
      
      === Clustering model (full training set) ===
      
      <생략>
      
      Time taken to build model (full training data) : 0.82 seconds
      
      === Model and evaluation on training set ===
      
      Clustered Instances
      
      0       400 ( 31%)
      1       200 ( 15%)
      2       698 ( 54%)
      3         2 (  0%)
      ```

    * complete, average

      ```text
      === Run information ===
      
      Scheme:       weka.clusterers.HierarchicalClusterer -N 4 -L COMPLETE -P -A "weka.core.EuclideanDistance -R first-last"
      Relation:     /cluster2
      Instances:    1300
      Attributes:   3
                    x
                    y
                    label
      Test mode:    evaluate on training data
      
      
      === Clustering model (full training set) ===
      
      <생략>
      
      Time taken to build model (full training data) : 1.1 seconds
      
      === Model and evaluation on training set ===
      
      Clustered Instances
      
      0       194 ( 15%)
      1       206 ( 16%)
      2       200 ( 15%)
      3       700 ( 54%)
      ```

    * mean, centroid

      ```text
      Time taken to build model (full training data) : 0.87 seconds
      
      === Model and evaluation on training set ===
      
      Clustered Instances
      
      0       181 ( 14%)
      1       219 ( 17%)
      2       200 ( 15%)
      3       700 ( 54%)
      ```

    * ward

      ```text
      Time taken to build model (full training data) : 2.85 seconds
      
      === Model and evaluation on training set ===
      
      Clustered Instances
      
      0       210 ( 16%)
      1       190 ( 15%)
      2       200 ( 15%)
      3       700 ( 54%)
      ```

    * adjcomplete

      ```text
      Time taken to build model (full training data) : 23.21 seconds
      
      === Model and evaluation on training set ===
      
      Clustered Instances
      
      0       210 ( 16%)
      1       190 ( 15%)
      2       200 ( 15%)
      3       700 ( 54%)
      ```

    * neighbor_joining : 무슨 방법이길래 네 개가 나오지도 않았을까

      ```text
      Time taken to build model (full training data) : 1.73 seconds
      
      === Model and evaluation on training set ===
      
      Clustered Instances
      
      0      1300 (100%)
      ```

  * python으로 실습 > jn에서

  * 구형에 강한, 분산병렬처리 불가, outlier 영향 받음

* Density-Based

  * K개 지정하지 않음

  * '인싸(core point)들을 찾아라'가 핵심

  * Eps와 MinPts 설정

  * outlier 제외 - 정확도 상승

  * 단점: Eps와 MinPts에 민감한 방식. 설정값을 잘 줘야 함.

  * weka

    * dbscan은 기본 제공이 아니라 다른 사람들이 만들어준 걸 다운받아야 함

    * tools > pakage manager > optics_dbScan install

    * 자료 열고 cluster > dbscan

    * epsilon 0.05, minPoints 20으로 실행해보기 - outlier 엄청 많음. 잘못된 세팅.

    * epsilon이 커지거나 minPoints가 작아지면 큰 cluster를 찾는 데 도움

      * 0.3, 20 / 0.1, 40 / 0.15, 60 / 0.06, 6 (답안)

        ```text
        Clustered Instances
        
        0       400 ( 31%)
        1       700 ( 54%)
        2       200 ( 15%)
        ```

  * python으로

* EM Clustering

  * Generative Model

  * Gaussian mixture

  * weka

    * numClusters : -1 (EM 알고리즘이 임의로 찾아줌), 지정도 가능

    * 4 : 결과 가장 예쁘게 잘 나왔음

      ```text
      Time taken to build model (full training data) : 0.19 seconds
      
      === Model and evaluation on training set ===
      
      Clustered Instances
      
      0       200 ( 15%)
      1       200 ( 15%)
      2       700 ( 54%)
      3       200 ( 15%)
      
      
      Log likelihood: -0.18954
      ```

    * -1

      ```text
      
      Time taken to build model (full training data) : 35.56 seconds
      
      === Model and evaluation on training set ===
      
      Clustered Instances
      
       0       144 ( 11%)
       1       115 (  9%)
       2        63 (  5%)
       3       120 (  9%)
       4       158 ( 12%)
       5       200 ( 15%)
       6       179 ( 14%)
       7       137 ( 11%)
       8        53 (  4%)
       9       131 ( 10%)
      
      
      Log likelihood: -0.05844
      ```

    * parameter를 잘 주지 않으면 위처럼 비효율적인 결과가

  * python (bixby 문제로 나가 있느라 끝부분 일부 듣지 못함)

* PLSI

  * 