# 빅데이터

> 빅데이터 활용의 가장 대표적인 예: 추천 시스템

* 빅데이터 분석이 필요한 이유
  * 현재 가장 빠른 속도로 증가하는 데이터는 사람이 만들어내는 데이터
  * 매일 25억 GB의 데이터 생성
  * 데이터가 많아질수록 정확도 증가
    * 알고리즘들의 정확도가 수렴하여 결과가 같아짐
  * 가장 좋은 알고리즘보다 데이터를 가장 많이 가진 것이 더 정확
* 빅데이터 분석 성공 사례
  * John Deere
    * 농장 트랙터를 현장 데이터 통제 센터로 만들고자
    * 기상 데이터 분석 회사 Climate Corporation 구매
  * Schindler elevator's smart systems
    * IoT 사용 실시간 유지 관리 시스템으로 센서 기술과 모바일 앱을 연결하여 2만 명 이상의 현장 근로자를 위한 '디지털 도구 사례' 만듦.
    * 이를 통해 서비스 엔지니어는 고객이 문제를 인식하기 전에 미리 해결 가능.
  * ALEX AND ANI
    * iBeacon을 이용하여 가게에 가까운 사람들 유도
    * 가게 내 고객의 구매 상품을 추적하여 스마트한 추천
    * 고객들의 동선을 추적하여 최적화된 상품 진열 결정
  * 남아프리카 대규모 천체 망원경
  * Airbus Factory
  * 미국 LA 경찰
    * 북부 샌 페르난도 밸리 지역 한 경찰서에서 향후 12시간 내 범죄 발생 가능성 가장 높은 지역을 예측하고 순찰.
    * 범죄 예측 후 빈집 절도 26% 감소.
    * 현재 미국 151개 도시에서 시범 운영 중.
    * 유용성 검증되며 전 지역으로 확대 예정.
  * Southwest
    * 잠재적 오작동이나 안전 문제 패턴을 알아내기 위해 비행기의 센서 데이터 분석
    * 항공사는 잠재적인 문제를 해결하고 항공편을 중단하거나 승객 위험 없이 필요한 수리를 할 수 있음.
  * Aurora
    * 의료 보험사. 질병 트랜드 예측. 
  * Time Warner
    * 영상 서비스 관련
  * KAYAK
    * 특정 비행 가격이 다음 주 내에 올라갈지 또는 내려갈지를 예측
    * 가장 저렴한 항공편, 인기있는 목적지 등 제공
  * Spotify
    * 음악 스트리밍 서비스
* 빅데이터 분석과 병렬 분산 처리 알고리즘
  * Moore의 법칙의 전성시대가 막을 내리는 중
    * 원자 단위로 내려가다보니 물리학적인 한계로 더는 CPU를 4년마다 2배씩 빠르게 할 수 없음.
  * Scale-out
    * 아주 많은 값싼 commodity low-end 서버들 이용
  * Scale-up
    * 적은 수의 값비싼 high-end 서버들 이용
  * Data-intensive한 분야에서는 아주 많은 값싼 commodity low-end 서버들을 이용하는 것을 선호
  * High-end machine들은 가격 관점에서는 선형으로 성능이 증가하지 않음
* 빅데이터 분석과 맵리듀스(MapReduce)
  * 맵리듀스
    * 대규모 컴퓨팅을 잘 분산하여 병렬 처리할 수 있도록 해준 첫 번째 프로그래밍 모델
    * 그러나 구글이 코드를 공개하지 않음
  * Hadoop
    * Java 기반, 맵리듀스를 모방하여 만들어낸 오픈소스 프로그램
    * 유저가 map, reduce, 그리고 main 함수들만 프로그래밍하면 됨
* 정리
  * 빅데이터는 미래 경쟁력의 핵심
    * 데이터의 폭발적 증가
    * 데이터 마이닝 기술이 큰 기여
    * 선진국의 집중적인 투자

### 프로젝트 설명

* 영화 추천 시스템
  * 넷플릭스, 유튜브에서 많이 사용하는 기법
  * 물론 훨씬 하이엔드, 최적화도 잘 되어있겠지만
  * 10년 전부터 널리 사용된 basic한 기술들을 활용하여 구현하는 게 목표
* 프로젝트 개요
  * 영화 평점 데이터를 이용하여 유사한 유저들 또는 유사한 영화들을 보여주며 여러가지 클러스터링 알고리즘들을 이용하여 분석
  * 영화 평점 빅 데이터를 이용하여 추천 시스템의 방법 중 하나인 협업 필터링(Collaborative Filtering)의 여러 알고리즘들을 Python 언어로 효율적으로 구현하여 실제 회사에 취업 시 필요한 지식과 코딩 능력 배양
* 프로젝트 2 목표
  * Django를 이용하여 실제 어플리케이션 UI 구현
  * Python 언어의 numpy와 scipy 라이브러리를 사용하여 행렬을 표현하고 연산하는 기본적인 함수들을 이해하고 효율적으로 사용
    * Sparce matrix(희소 행렬) 형태의 데이터를 Array에 그대로 저장하면 메모리도 많이 필요하고 수행 시간도 오래 걸림
    * Python numpy 라이브러리의 행렬 연산과 scipy 라이브러리의 Sparse matrix format을 이용하여 효율적 코딩
  * Django와 Python으로 구현하여 MovieLens 영화 데이터의 평점 행렬을 보고 ... 여러가지 클러스터링 알고리즘... 파이썬 라이브러리에서 기본적으로 제공하는 머신러닝 알고리즘을 이용하여...
* 프로젝트 3 목표
  * 영화 추천 시스템 이해
  * 협업 필터링 주요 알고리즘 이해
    * Matrix factorization + PLSI + LDA + KNN
  * 빅데이터 분석에 많이 쓰이는 Probabilistic Modeling 기술 습득
  * 평점 외 다른 정보도 이용하는 알고리즘 구현
    * 줄거리, 소셜 네트워크 등
  * Python을 사용하여 빅데이터 처리에 효율적인 코딩 실습
* 프로젝트 설명
  * 개발 환경 구성
    * Python 최신 버전
    * cmd 관리자 모드에서 pip install numpy, pip install scipy
    * Python 환경을 위한 virtualenvwrapper 설치
    * Django 설치
    * 추후 샘플 코드 받아서
  * Clustering
  * Model Training
* 플러스 알파
  * UI 예쁘게
  * 영화 포스터, 예고편, 동영상, 리뷰를 추천 시 함께 보여주기
  * 멀티 코어나 GPU를 잘 이용하도록 Python 코드 구현
  * 영화 줄거리 텍스트 외 다른 정보도 추천에 사용
  * 기계학습 툴들을 이용하여 PLSI 대신에 딥러닝 알고리즘 접목
  * 하둡의 MapReduce 프레임워크를 이용하여 병렬분산으로 세 가지 알고리즘 구현 (Python도 가능)
  * 복잡한 실제 데이터를 이용한 추천 시스템 개발
    * Tweeter에서 유저들에게 관심 가는 Tweet message나 follow할 사람들 추천

### Clustering

* 주어진 데이터를 비슷한 것끼리 분류하는 것
* Clustering
  * Given : Data points and number of desired clusters K
  * Group the data points into K clusters
* 다양한 활용
  * 백화점 고객 구매 상품에 따라 클러스터링
  * 고객 과거 패턴으로 추천 시스템
  * Gene 데이터 유사도에 따라 클러스터링
  * 텍스트 문서들을 주제에 따라 클러스터링
  * 유사한 이미지들 클러스터링
  * Call center에서 고객과 통화한 내용 텍스트 변환하여 ... 요약 정보 만들어냄
* Similarity
  * 거리가 가까울 수록 유사도가 높다고 판단.
  * 클러스터 중심점과의 거리가 가깝다면 해당 클러스터에 속할 가능성이 높다.
  * 잘 클러스터링하면 클러스터 센터와 각 지점 간 거리의 합이 작아진다.
  * measure 중심이라 다른 관점으로는 좋지 않을 수 있다.
* K-means Clustering Algorithms
  * K 개의 클러스터의 센터 점들을 찾고 모든 점에 대해 계산해 거리를 비교, 더 가까운 쪽 클러스터에 넣기.
  * 결과가 달라지지 않을 때까지 반복.
  * 단점
    * 단순한 거리 사용 - 원형 클러스터만 잘 찾음.
    * 클러스터 사이즈와 밀도에 영향을 매우 많이 받음.
    * 외톨이가 없다고 가정하기에 튀는 값이 있어도 그룹에 넣어버림.
  * K medoids
    * 클러스터마다 대표자 몇 개를 뽑아 사용하는 방법
    * 좀 더 많은 계산이 필요하지만, 좀 더 나은 결과
* 하이라티컬(?) 클러스터링
  * 굉장히 작게 해놓고 합치는 방법. 찾아보세요.
* EM Clustering
  * 확률을 이용
  * Generative model (생성 모델)
    * 데이터 생성 과정을 상상하는 것
    * 숨겨진 파라미터에 의해 데이터가 만들어졌다는 전제에서 시작
    * 가장 높은 확률로 이 데이터를 만들어낸 경우를 찾아내는 것
  * Likelihood
    * 고정된 parameter에서 주어진 data를 만들어낼 확률
    * 이 확률이 가장 높은 parameter 조합을 찾아내는 것
  * 다른 데이터가 들어왔을 때, 찾아놓은 model parameter로 어느 cluster에 있는지 찾아낸다.
  * EM Algorithm
    * 확률 모델을 찾아내기 위해 사용
    * Known data observation을 이용하여 Unknown parameters를 찾아내는 것. 
    * Local Maximum : 전체에서 가장 좋은 파라미터라는 건 보장을 못 함.
      * 여러번 다른 조합으로 해봐야 함.
      * 가끔 더 좋은 답이 있는데도 덜 좋은 답을 낼 수 있다는 것.
    * Maximum Likelihood를 찾아내는 것이 목적
* Practice
  * one dimensional data로 연습할 것
  * Gaussian mixture
    * cluster 개수만큼의 정규분포가 있다고 가정
    * 그 정규분포로부터 data가 생성되었다고 가정
  * 어떤 점들이 각 Cluster에 속했을지, 정규분포를 어떻게 형성했을지
    * Weight(파이), Mean(뮤), Variance(시그마)
    * 각 정규분포의 이 parameter들을 유추하는 게 EM Clustering Algorithm
  * Likelihood 식을 활용하여 각 변수에 대한 확률 계산 (모든 데이터)
    * Likelihood-Probability of X = {x1, ..., xn} to be generated from our K-Gaussian mixture model
    * 결과값이 굉장히 작은 값이므로 로그 취함. (미분해 기울기가 0인 지점을 찾는 게 목표였으므로 로그 함수가 편함, 로그 전후 맥시멈 지점도 같으므로.)
  * EM : Expectation Maximize 의 E - Step
    * Compute expectation of hidden variables given observed variables
  * M - Step
    * 조건 : 각 봉우리의 합 (파이의 합) 이 1이 되어야 한다는 조건. (Constraint)
    * Lagrangean function으로 해당 Constraint가 주어졌을 때 Optimize 가능. 마치 Constraint가 없는 것처럼 Optimize 가능.
  * EM-Means Clustering으로 웬만한 데이터에 대해서는 Cluster를 잘 찾을 수 있음. 
* PLSI(Probabilistic Latent Semantic Indexing)
  * EM Algorithm 활용
  * 가정
    * topic 선정
    * topic에 따른 word 선정
    * 위 두 단계를 반복하여 글을 작성한다.
    * 모든 단어를 독립적으로 선택한다고 가정.
    * d(Document) - z(Topic) - w(Word)
    * di: the i-th document(observable)
    * zk: the k-th latent topic(unobservable)
    * wv: the v-th word (observable)
  * 목적: 주어진 observable data로부터 unobservable한 hidden parameter를 찾는 것.
  * 주어진 데이터를 만들기 위한 Likelihood 계산.
    * i번째 document를 선택할 확률
    * i번째 document에서 k번째 topic을 선택할 확률
    * k 번째 topic에 대한 단어 중 v번째 단어를 선택할 확률
    * marginalization 사용.
    * 단어는 순수하게 topic에만 영향, document에는 영향 받지 않는다고 가정
    * n(di, wv): 해당 도큐먼트에서 해당 단어가 나온 횟수
    * E-step, M-step을 거쳐 구함
  * sample
    * 하나의 토픽에서 각 단어가 선택될 확률의 합은 1
    * 하나의 도큐먼트에서 각 토픽이 선택될 확률의 합은 1
    * random하게 각 확률을 asign한 후, 모든 조합에 대해 topic이 뽑힐 확률 계산 (E-step)
    * initialize한 parameter를 계산한 값으로 update (M-step)
    * iteration 반복하여 update 반복. 값이 더는 변동이 없을 때 반복 중단하고 모델 파라미터 확정. (topic - word) - topic 짐작 가능해짐
* Matrix Factorization
  * 통상적으로 Content based filtering을 이용. 
    * 각 item 간 similarity를 이용하여 추천.
    * 별 연관성이 없기도.
  * Collaboration filtering method
    * 각각의 유저는 비슷한 유저와 동일하게 행동한다는 가정
    * usage 또는 preference pattern 활용
  * customer similarity matrix W 를 만든다.
    * 가장 간단한 방법: vector 내적
  * User Similarity 이용하여 선호도 예측 (matrix 곱으로)
  * Model Based Method
    * 과거 rating을 base로 model...
  * Matrix Factorization
    * 하나의 Matrix를 두 개 Matrix의 곱으로 만들어 내는 것
    * Rating Matrix를 만들어내는 User Vector와 Item Vector를 찾겠다.
    * rij ~= uT의 i번 * v의 j번
  * Given
    * R
  * Loss Minimize가 목표
    * U 와 V 로 예측한 matrix 가 R과 같게 하는 것이 목표
  * 머신러닝 쪽 원리로 이상한 값을 찾는 걸 제거 (트레이닝을 효율적으로)
  * V과 U가 우리가 찾아야 하는 hidden vector
    * 업데이트로 찾아낼 것
  * 이후 모르는 rij를 V와 U로 예측
* Improving Matrix Factorization
  * 영화 줄거리로부터 PLSI 모델 이용하여 비슷한 영화를 묶어 추가로 넣어줄 수 있음
  * PLSI, LDA 등 여러 모델 활용 가능
  * Clustering 정보를 Item Vector로 활용하면 컨텐츠를 반영할 수 있음.
  * Model, Likelihood, item의 update 식이 변경됨 (세타 in) (user update식은 변경 없음)

* 말씀드린 것들을 인터넷에서 검색해서 찾아보세요. 구현되어있는 코드도 참조해보고.

### 프로젝트

* 개요 (앞에 적음)
* 프로젝트 2 목표 (앞에 적음)
  * 유사도에 따른 TOP-K 검색 구현
  * 클러스터링 알고리즘 구현
    * 파이썬 라이브러리로 구현된 것도 있음
* 프로젝트 3 목표 (앞에 적음)
  * 영화 추천 시스템
  * Collaborative Filtering
    * K-nearest neighbor : 가장 가까운 사람 K 명을 보고 다수를 따라 클러스터에 들어가는 알고리즘
    * Matrix factorization
    * M f + PLSI
    * M f + LDA
  * 줄거리, 소셜 네트워크 등
* 플러스알파 (앞에 적음)

### Tools

* Anaconda
  * Jupyter, Numby, SciPy, pandas, TensorFlow 등을 지원하는 python 종합 툴
* Jupyter Notebook
  * Anaconda 설치 시 같이 생성
* Codecademy
  * python, php, c# 등 튜토리얼 제공
  * 회원가입 시 프로 과정은 7일 무료 트라이얼이 있는데 python3는 25시간 정도로 짧으니 해볼만함
* scikit-learn : python 라이브러리
  * 머신러닝 알고리즘들이 다수 구현되어있는 라이브러리
  * Clustering, LDA 알고리즘 포함
  * example도 제공
* TensorFlow
  * 구글에서 개발한 오픈소스
  * 배경지식이 좀 많이 요구됨

### Q&A

* AI 딥러닝 사용은 선택사항
* 머신러닝 라이브러리 받아서 쓰면 노트북에서도 잘 돌아감
* MovieLens : 영화 추천 연구를 위해 만들어놓은 데이터
* 영화 db 사이트에서 추가 데이터 얻을 수 있음

